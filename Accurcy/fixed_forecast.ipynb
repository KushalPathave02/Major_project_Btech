{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Time Series Forecasting: ARIMA, SARIMA, Holt-Winters, Prophet, LSTM\n",
    "\n",
    "## Fixed Version - Compatible with All Scikit-learn Versions\n",
    "\n",
    "This notebook uses your local CSV file directly:\n",
    "- File: `/Users/kushal/Downloads/Major_project-main/Accurcy/expenses_income_summary.csv`\n",
    "- Compares 5 forecasting algorithms\n",
    "- Shows accuracy metrics and winner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages (uncomment if needed)\n",
    "# !pip install -q numpy pandas matplotlib seaborn scikit-learn statsmodels prophet tensorflow\n",
    "\n",
    "print(\"üì¶ Starting analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Classical models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Prophet\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    Prophet = None\n",
    "    PROPHET_AVAILABLE = False\n",
    "    print('Prophet not available')\n",
    "\n",
    "# TensorFlow for LSTM\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    tf = None\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "    print('TensorFlow not available')\n",
    "\n",
    "print(f'‚úÖ Prophet available: {PROPHET_AVAILABLE}')\n",
    "print(f'‚úÖ TensorFlow available: {TENSORFLOW_AVAILABLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV File Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct file path\n",
    "CSV_PATH = '/Users/kushal/Downloads/Major_project-main/Accurcy/expenses_income_summary.csv'\n",
    "TARGET_TYPE = 'EXPENSE'  # Change to 'INCOME' if needed\n",
    "TEST_RATIO = 0.2  # 20% for testing\n",
    "\n",
    "def load_data(csv_path):\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f'‚ùå CSV file not found: {csv_path}')\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f'üìä Raw data shape: {df.shape}')\n",
    "    print(f'üìä Columns: {list(df.columns)}')\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required = {'Date','amount','type'}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'‚ùå Missing columns in CSV: {missing}')\n",
    "    \n",
    "    # Parse date\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    \n",
    "    # Clean amounts (remove commas)\n",
    "    df['amount'] = (df['amount']\n",
    "        .astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .astype(float))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "print(f'üìÅ Loading CSV from: {CSV_PATH}')\n",
    "df_raw = load_data(CSV_PATH)\n",
    "\n",
    "print(f'\\nüìà Date range: {df_raw[\"Date\"].min()} to {df_raw[\"Date\"].max()}')\n",
    "print(f'üìà Types available: {df_raw[\"type\"].unique()}')\n",
    "print(f'üìà Total transactions: {len(df_raw)}')\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Daily Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by target type and aggregate daily\n",
    "assert TARGET_TYPE in {'EXPENSE','INCOME'}\n",
    "df = df_raw[df_raw['type'] == TARGET_TYPE].copy()\n",
    "df = df[['Date','amount']].sort_values('Date')\n",
    "\n",
    "# Aggregate to daily totals\n",
    "daily = (df.set_index('Date')['amount']\n",
    "         .resample('D').sum().fillna(0.0))\n",
    "daily.name = TARGET_TYPE\n",
    "\n",
    "print(f'üìä Daily series created:')\n",
    "print(f'üìä Date range: {daily.index.min()} ‚Üí {daily.index.max()}')\n",
    "print(f'üìä Total days: {len(daily)}')\n",
    "print(f'üìä Total {TARGET_TYPE}: ‚Çπ{daily.sum():.2f}')\n",
    "print(f'üìä Average daily {TARGET_TYPE}: ‚Çπ{daily.mean():.2f}')\n",
    "print(f'üìä Days with zero {TARGET_TYPE}: {(daily == 0).sum()}')\n",
    "\n",
    "# Plot the series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(daily.index, daily.values, alpha=0.8)\n",
    "plt.title(f'Daily {TARGET_TYPE} Time Series')\n",
    "plt.ylabel('Amount (‚Çπ)')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nüìä Last 10 days:')\n",
    "daily.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrono_train_test_split(series, test_ratio=0.2):\n",
    "    n = len(series)\n",
    "    h = max(1, int(n * test_ratio))\n",
    "    train = series.iloc[:-h]\n",
    "    test = series.iloc[-h:]\n",
    "    return train, test\n",
    "\n",
    "y_train, y_test = chrono_train_test_split(daily, TEST_RATIO)\n",
    "\n",
    "print(f'üîÑ Train/Test Split:')\n",
    "print(f'üîÑ Train size: {len(y_train)} days')\n",
    "print(f'üîÑ Test size: {len(y_test)} days')\n",
    "print(f'üîÑ Train period: {y_train.index.min()} to {y_train.index.max()}')\n",
    "print(f'üîÑ Test period: {y_test.index.min()} to {y_test.index.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics (FIXED VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    denom = np.where(y_true == 0, 1e-8, np.abs(y_true))\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "def evaluate(y_true, y_pred, model_name='Model'):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    # FIXED: Use np.sqrt instead of squared parameter\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mp = mape(y_true, y_pred)\n",
    "    print(f'üìà {model_name} - MAE: ‚Çπ{mae:.2f}, RMSE: ‚Çπ{rmse:.2f}, MAPE: {mp:.2f}%')\n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mp}\n",
    "\n",
    "print('‚úÖ Evaluation functions ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîÑ Training ARIMA model...')\n",
    "arima_forecast = None\n",
    "try:\n",
    "    arima_model = ARIMA(y_train, order=(1,1,1))\n",
    "    arima_fit = arima_model.fit()\n",
    "    arima_forecast = arima_fit.forecast(steps=len(y_test))\n",
    "    arima_metrics = evaluate(y_test.values, arima_forecast, 'ARIMA(1,1,1)')\n",
    "    print('‚úÖ ARIMA completed!')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå ARIMA failed: {e}')\n",
    "    arima_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ SARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîÑ Training SARIMA model...')\n",
    "sarima_forecast = None\n",
    "try:\n",
    "    sarima_model = SARIMAX(y_train, order=(1,1,1), seasonal_order=(1,1,1,7))\n",
    "    sarima_fit = sarima_model.fit(disp=False)\n",
    "    sarima_forecast = sarima_fit.forecast(steps=len(y_test))\n",
    "    sarima_metrics = evaluate(y_test.values, sarima_forecast, 'SARIMA(1,1,1)(1,1,1,7)')\n",
    "    print('‚úÖ SARIMA completed!')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå SARIMA failed: {e}')\n",
    "    sarima_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Holt-Winters Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîÑ Training Holt-Winters model...')\n",
    "hw_forecast = None\n",
    "try:\n",
    "    hw_model = ExponentialSmoothing(y_train, trend='add', seasonal='add', seasonal_periods=7)\n",
    "    hw_fit = hw_model.fit(optimized=True)\n",
    "    hw_forecast = hw_fit.forecast(len(y_test))\n",
    "    hw_metrics = evaluate(y_test.values, hw_forecast.values, 'Holt-Winters')\n",
    "    print('‚úÖ Holt-Winters completed!')\n",
    "except Exception as e:\n",
    "    try:\n",
    "        # Fallback without seasonality\n",
    "        hw_model = ExponentialSmoothing(y_train, trend='add')\n",
    "        hw_fit = hw_model.fit(optimized=True)\n",
    "        hw_forecast = hw_fit.forecast(len(y_test))\n",
    "        hw_metrics = evaluate(y_test.values, hw_forecast.values, 'Holt-Winters (no seasonal)')\n",
    "        print('‚úÖ Holt-Winters (simplified) completed!')\n",
    "    except Exception as e2:\n",
    "        print(f'‚ùå Holt-Winters failed: {e2}')\n",
    "        hw_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîÑ Training Prophet model...')\n",
    "prophet_forecast = None\n",
    "if not PROPHET_AVAILABLE:\n",
    "    print('‚ùå Prophet not available')\n",
    "    prophet_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "else:\n",
    "    try:\n",
    "        df_p = y_train.reset_index().rename(columns={'Date':'ds', TARGET_TYPE:'y'})\n",
    "        m = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=False)\n",
    "        m.fit(df_p)\n",
    "        future = pd.DataFrame({'ds': y_test.index})\n",
    "        fc = m.predict(future)\n",
    "        prophet_forecast = fc['yhat'].values\n",
    "        prophet_metrics = evaluate(y_test.values, prophet_forecast, 'Prophet')\n",
    "        print('‚úÖ Prophet completed!')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Prophet failed: {e}')\n",
    "        prophet_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üîÑ Training LSTM model...')\n",
    "lstm_forecast = None\n",
    "if not TENSORFLOW_AVAILABLE:\n",
    "    print('‚ùå TensorFlow not available')\n",
    "    lstm_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "else:\n",
    "    try:\n",
    "        # Scale data\n",
    "        scaler = MinMaxScaler()\n",
    "        y_train_vals = y_train.values.reshape(-1,1)\n",
    "        scaler.fit(y_train_vals)\n",
    "        y_train_scaled = scaler.transform(y_train_vals)\n",
    "        \n",
    "        # Create sequences\n",
    "        WINDOW = min(14, len(y_train_scaled) // 2)\n",
    "        def make_sequences(arr, window):\n",
    "            X, y = [], []\n",
    "            for i in range(window, len(arr)):\n",
    "                X.append(arr[i-window:i, 0])\n",
    "                y.append(arr[i, 0])\n",
    "            return np.array(X), np.array(y)\n",
    "        \n",
    "        X_tr, y_tr = make_sequences(y_train_scaled, WINDOW)\n",
    "        if len(X_tr) < 5:\n",
    "            raise RuntimeError('Not enough data for LSTM')\n",
    "        \n",
    "        X_tr = X_tr.reshape((X_tr.shape[0], X_tr.shape[1], 1))\n",
    "        \n",
    "        # Build model\n",
    "        model = keras.Sequential([\n",
    "            layers.Input(shape=(WINDOW,1)),\n",
    "            layers.LSTM(32),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        model.fit(X_tr, y_tr, epochs=50, batch_size=min(16, len(X_tr)), verbose=0)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        hist = list(y_train_scaled[-WINDOW:, 0])\n",
    "        preds = []\n",
    "        for _ in range(len(y_test)):\n",
    "            x = np.array(hist[-WINDOW:]).reshape((1, WINDOW, 1))\n",
    "            p = model.predict(x, verbose=0)[0,0]\n",
    "            preds.append(p)\n",
    "            hist.append(p)\n",
    "        \n",
    "        lstm_forecast = scaler.inverse_transform(np.array(preds).reshape(-1,1)).ravel()\n",
    "        lstm_metrics = evaluate(y_test.values, lstm_forecast, 'LSTM')\n",
    "        print('‚úÖ LSTM completed!')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå LSTM failed: {e}')\n",
    "        lstm_metrics = {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ FINAL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = []\n",
    "results.append({'Model':'ARIMA', **arima_metrics})\n",
    "results.append({'Model':'SARIMA', **sarima_metrics})\n",
    "results.append({'Model':'Holt-Winters', **hw_metrics})\n",
    "results.append({'Model':'Prophet', **prophet_metrics})\n",
    "results.append({'Model':'LSTM', **lstm_metrics})\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "# Sort by RMSE (lower is better)\n",
    "res_df_sorted = res_df.sort_values('RMSE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ ALGORITHM ACCURACY COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(res_df_sorted.to_string(index=False, float_format='%.2f'))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find best model\n",
    "valid_results = res_df_sorted.dropna(subset=['RMSE'])\n",
    "if len(valid_results) > 0:\n",
    "    best_model = valid_results.iloc[0]['Model']\n",
    "    best_rmse = valid_results.iloc[0]['RMSE']\n",
    "    best_mae = valid_results.iloc[0]['MAE']\n",
    "    best_mape = valid_results.iloc[0]['MAPE']\n",
    "    \n",
    "    print(f\"\\nü•á WINNER: {best_model}\")\n",
    "    print(f\"üìä RMSE: ‚Çπ{best_rmse:.2f} (Root Mean Square Error)\")\n",
    "    print(f\"üìä MAE: ‚Çπ{best_mae:.2f} (Mean Absolute Error)\")\n",
    "    print(f\"üìä MAPE: {best_mape:.2f}% (Mean Absolute Percentage Error)\")\n",
    "    print(f\"\\nüí° {best_model} is the most accurate algorithm for your {TARGET_TYPE} forecasting!\")\n",
    "    print(f\"\\nüöÄ Use {best_model} in your Flask application for best results!\")\n",
    "else:\n",
    "    print(\"‚ùå No valid results found\")\n",
    "\n",
    "res_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main forecast plot\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Plot train and test data\n",
    "plt.plot(y_train.index, y_train.values, label='Train Data', color='blue', alpha=0.6)\n",
    "plt.plot(y_test.index, y_test.values, label='Actual Test', color='black', linewidth=3, marker='o')\n",
    "\n",
    "# Plot forecasts\n",
    "if arima_forecast is not None: \n",
    "    plt.plot(y_test.index, arima_forecast, label='ARIMA', linestyle='--', alpha=0.8, linewidth=2)\n",
    "if sarima_forecast is not None: \n",
    "    plt.plot(y_test.index, sarima_forecast, label='SARIMA', linestyle='--', alpha=0.8, linewidth=2)\n",
    "if hw_forecast is not None: \n",
    "    plt.plot(y_test.index, hw_forecast, label='Holt-Winters', linestyle='--', alpha=0.8, linewidth=2)\n",
    "if prophet_forecast is not None: \n",
    "    plt.plot(y_test.index, prophet_forecast, label='Prophet', linestyle='--', alpha=0.8, linewidth=2)\n",
    "if lstm_forecast is not None: \n",
    "    plt.plot(y_test.index, lstm_forecast, label='LSTM', linestyle='--', alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.title(f'{TARGET_TYPE} Forecasting: All Models Comparison', fontsize=16)\n",
    "plt.ylabel('Amount (‚Çπ)', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zoomed plot - test period only\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(y_test.index, y_test.values, label='Actual', color='black', linewidth=4, marker='o', markersize=8)\n",
    "\n",
    "if arima_forecast is not None: \n",
    "    plt.plot(y_test.index, arima_forecast, label='ARIMA', marker='s', alpha=0.8, linewidth=2)\n",
    "if sarima_forecast is not None: \n",
    "    plt.plot(y_test.index, sarima_forecast, label='SARIMA', marker='^', alpha=0.8, linewidth=2)\n",
    "if hw_forecast is not None: \n",
    "    plt.plot(y_test.index, hw_forecast, label='Holt-Winters', marker='d', alpha=0.8, linewidth=2)\n",
    "if prophet_forecast is not None: \n",
    "    plt.plot(y_test.index, prophet_forecast, label='Prophet', marker='v', alpha=0.8, linewidth=2)\n",
    "if lstm_forecast is not None: \n",
    "    plt.plot(y_test.index, lstm_forecast, label='LSTM', marker='*', alpha=0.8, linewidth=2, markersize=10)\n",
    "\n",
    "plt.title(f'{TARGET_TYPE} Forecasts - Test Period Detail', fontsize=16)\n",
    "plt.ylabel('Amount (‚Çπ)', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if 'best_model' in locals():\n",
    "    print(f\"\\n‚úÖ Analysis complete! Best algorithm: {best_model} with RMSE: ‚Çπ{best_rmse:.2f}\")\n",
    "    print(f\"üí° Implement {best_model} in your Flask forecast.py route!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
